{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29ce5bd9",
   "metadata": {},
   "source": [
    "<center><h1>Artificial Intelligence Journals Ranking (2000 - 2021)</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f9820c",
   "metadata": {},
   "source": [
    "<center><h3>Vásquez, V., Cruz, J. & Henao, M.</h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f4680e",
   "metadata": {},
   "source": [
    "<center><h2 style=\"margin-top:50px;\">Abstract</h2></center>\n",
    "<p>SCImago Journal & Country Rank is a publicly available portal that includes the journals and country scientific indicators developed from the Scopus database. With the dataset used in this document, it is possible to determine the trends of the subtopics covered in the documents published throughout the years and which journals are the most significant in the area.</p>\n",
    "\n",
    "<strong>Keywords:</strong> Artificial Intelligence, Data analisis, Journal ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eee2269",
   "metadata": {},
   "source": [
    "<h2>0. Setting Up Environment</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c92c281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System variables\n",
    "import os \n",
    "from glob import glob\n",
    "\n",
    "# Data processing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Dataset connection\n",
    "import opendatasets as od\n",
    "\n",
    "# Graphic tools \n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b8c1d8",
   "metadata": {},
   "source": [
    "<h3>0.1. Download Dataset</h3>\n",
    "\n",
    "<p>The dataset is downloaded from Kaggle using the opendatasets library.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025cd7af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ================\n",
    "# Download dataset\n",
    "# ================\n",
    "od.download(\"https://www.kaggle.com/datasets/yasirabdaali/artificial-intelligence-journals-ranking-20002021\", \"../dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25710967",
   "metadata": {},
   "source": [
    "<h3>0.2. Reading Dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1d49ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_csvFiles (PATH = os.getcwd(),EXT = \"*.csv\"):  \n",
    "    \"\"\"\n",
    "    Retrieve all files with a given extension (EXT = *.csv by default) from current\n",
    "    working directory where the process is being implemented, using os.getcwd () \n",
    "    and the glob module, which finds all path names that resemble a specified pattern \n",
    "    according to the rules that are followed in a Unix terminal.\n",
    "    \n",
    "    Returns:6\n",
    "        Returns a list with all the files path of the given extension \n",
    "    \"\"\"\n",
    "    print(os.getcwd())\n",
    "    list_paths = []\n",
    "    for path, subdir, files in os.walk(PATH):\n",
    "        for file in glob(os.path.join(path, EXT)):\n",
    "            if file.find(\"scimagojr\") != -1:\n",
    "                list_paths.append(file)\n",
    "    return list_paths\n",
    "\n",
    "\n",
    "def concat_paths(all_paths):\n",
    "    \"\"\"receives a list of file directories with a CSV extension \n",
    "    and creates a dataset by concatenating each file\n",
    "    and assigning each file a year label that is stored in the \"Year\" column,\n",
    "    returning a dataframe\n",
    "\n",
    "    Returns: \n",
    "        Returns a dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    all_df = []\n",
    "    for path in all_paths:\n",
    "        df = pd.read_csv(path, sep = ';')        \n",
    "        df['Year'] = int(path.split()[1])\n",
    "        all_df.append(df)\n",
    "    \n",
    "    df = pd.concat(all_df, ignore_index=True)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7ef8a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juandiego\\Documents\\Programacion\\final_project_TEAM\\final_project_TGL2022\n"
     ]
    }
   ],
   "source": [
    "# ===========================================================================\n",
    "# The functions in charge of reading and joining the dataset tables are called\n",
    "# ===========================================================================\n",
    "df = concat_paths(path_csvFiles())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e564d1",
   "metadata": {},
   "source": [
    "<h2>1. Understanding the dataset</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae906b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# Display the columns that make up the dataset\n",
    "# ===========================================\n",
    "df.columns.values.tolist()[:21]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb8731f",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><b>Rank:</b>  Consecutive number assigned to records by table </li>\n",
    "    <li><b>Source ID:</b> Scopus Journal ID </li>\n",
    "    <li><b>Title:</b> Journal’s title</li>\n",
    "    <li><b>Type:</b> Type of publication (Journal, Book Series and Conference & Proceedings) </li>\n",
    "    <li><b>ISSN:</b> International Standard Serial Number  </li>\n",
    "    <li><b>SJR:</b> Weighted citations received in year X to documents published in the journal in years X-1, X-2 and X-3.</li>\n",
    "    <li>\n",
    "        <b>SJR Quartile:</b> Each thematic category is divided into quartiles.\n",
    "        <ul>\n",
    "            <li><b>Q1:</b> group made up of the first 25% of the journals on the list. </li>\n",
    "            <li><b>Q2:</b> group that occupies from 25% to 50% </li>\n",
    "            <li><b>Q3:</b> group that is positioned between 50% and 75% </li>\n",
    "            <li><b>Q4:</b> group that is positioned between 75% and 100% </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "<ul>\n",
    "    <li>\n",
    "        <b>H Index:</b>\n",
    "        The h index expresses the journal's number of articles (h) that have received at least h citations. It quantifies both journal scientific productivity and scientific impact and it is also applicable to scientists, countries, etc.\n",
    "    </li>\n",
    "    <li>\n",
    "        <b>Total Docs. (3years):</b>\n",
    "        Published documents in the three previous years\n",
    "    </li>\n",
    "    <li>\n",
    "        <b>Total Refs:</b>\n",
    "        All the bibliographical references in a journal in the selected period.\n",
    "    </li>\n",
    "    <li>\n",
    "        <b>Total Cites (3years):</b>\n",
    "        Number of citations received in the selected year by a journal to the documents published in the three previous years\n",
    "    </li>\n",
    "    <li>\n",
    "        <b>Citable Docs. (3years):</b>\n",
    "        Number of citable documents published by a journal in the three previous years\n",
    "    </li>\n",
    "    <li>\n",
    "        <b>Cites / Doc. (2years):</b>\n",
    "        Margin between citable documents and the total documents by a journal in the two previous years.\n",
    "    </li>\n",
    "    <li>\n",
    "        <b>Ref. / Doc:</b>\n",
    "        Margin between all the bibliographical references in a journal in the selected period and the total documents published\n",
    "    </li>\n",
    "    <li>\n",
    "        <b>Publisher:</b> Journal Publisher.\n",
    "    </li>\n",
    "    <li>\n",
    "        <b>Coverage:</b>\n",
    "        The length of time, e.g. years, for which journals are published.\n",
    "    </li>\n",
    "    <li>\n",
    "        <b>Categories:</b>\n",
    "        Journal key words\n",
    "    </li>\n",
    "</ul>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6ead0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d3e5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================================\n",
    "# Plot rectangular df as a color-encoded matrix\n",
    "# Visualization in heatmap of the columns that represent gaps to develop strategies to correct them\n",
    "# ===================================================================================================\n",
    "sns.heatmap(df.notnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01268c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "# Plot rectangular df as a color-encoded matrix. \n",
    "# In the Type column, the records that are 'Conference and Proceedings' are searched \n",
    "# and it is identified that in relation to the 'Coverage' and 'Publisher' columns, \n",
    "# most of the empty records are found\n",
    "# ===================================================================================\n",
    "sns.heatmap(df[(df['Type'] == \"conference and proceedings\")][[\"Type\",\"Coverage\",\"Publisher\"]].notnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd07b46",
   "metadata": {},
   "source": [
    "<h2>2. Preprocessing data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb665f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# Keep only 'Journal' and 'Book Series' type records\n",
    "# ==================================================\n",
    "df = df.loc[(df['Type'] == 'journal') | (df['Type'] == 'book series')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7510437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================================\n",
    "# The data of the 'Total Docs.20##' columns is stored in the 'Total Docs column. per year'\n",
    "# ========================================================================================\n",
    "df['Total Docs. per Year'] = df[list(df.filter(regex  = '20'))].fillna('').astype(str).apply(lambda x: \"\".join(x), axis =1)\n",
    "df['Total Docs. per Year'] = df['Total Docs. per Year'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe485157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# The columns 'Total Docs.20##' are eliminated\n",
    "# ============================================\n",
    "df.drop(list(df.filter(regex  = '20')), inplace = True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c139a58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# Explore the data type columns and identify an assignment error\n",
    "# ==============================================================\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c4d4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================================\n",
    "# Explore the values with the wrong mapping in detail and create a modification scheme\n",
    "# ====================================================================================\n",
    "\n",
    "for i in (5, 12, 13):\n",
    "    print(f\"\\033[1m {df.columns[i]}:\\n\\033[0m {list((df[df.columns[i]]))[:30]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec77c36d",
   "metadata": {},
   "source": [
    "<h2>2.1. Modification scheme</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34f6938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================================\n",
    "# The columns that were as an object with the float data type are established\n",
    "# ===========================================================================\n",
    "df['SJR'] = (df['SJR'].replace(',','.', regex=True).astype(float)).fillna(0)\n",
    "df['Cites / Doc. (2years)'] = (df['Cites / Doc. (2years)'].replace(',','.', regex=True).astype(float))\n",
    "df['Ref. / Doc.'] = (df['Ref. / Doc.'].replace(',','.', regex=True).astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6a05ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================================\n",
    "# The heatmap is made to verify the result of the treatment that was given to the columns that had empty\n",
    "# ======================================================================================================\n",
    "sns.heatmap(df.notnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041ce15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============\n",
    "# Numeric columns\n",
    "# ===============\n",
    "int_df = df.select_dtypes(include=['int64', 'float']).copy()\n",
    "print(f\"[{len(int_df)} rows x {len(int_df.columns)} columns]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d57ec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================================\n",
    "# Summarize the mean, standard deviation, min and max values in the dataframe\n",
    "# ===========================================================================\n",
    "int_df = int_df.reset_index(drop=True)\n",
    "int_df[['SJR', 'H index', 'Total Docs. per Year']].describe().loc[['mean', 'std', 'min', 'max']].applymap(lambda x: f\"{x:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd4e7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================\n",
    "# Categorical columns\n",
    "# ===================\n",
    "obj_df = df.select_dtypes(include=['object']).copy()\n",
    "print(f\"[{len(obj_df)} rows x {len(obj_df.columns)} columns]\\n\")\n",
    "\n",
    "#Categorical description\n",
    "obj_df[['Title', 'Country', 'Region', 'Publisher', 'Categories']].describe().loc[['count', 'unique']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb8a31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================\n",
    "# Categorical columns sets overview\n",
    "# =================================\n",
    "i=0\n",
    "while i<len(obj_df.columns):    \n",
    "    print((\"\\033[1m {}: \\n \\033[0m {}\\n\").format(obj_df.columns[i],list(set(obj_df[obj_df.columns[i]]))[:10]))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c437e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Download consolidated dataframe\n",
    "# ==============================\n",
    "df.to_csv('../dataset/journalAI.csv',sep = \";\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406061bf",
   "metadata": {},
   "source": [
    "<h2>Viz Context</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bda31f1",
   "metadata": {},
   "source": [
    "<h2>References</h2>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "36cf16204b8548560b1c020c4e8fb5b57f0e4c58016f52f2d4be01e192833930"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
